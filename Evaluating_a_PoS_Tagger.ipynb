{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dana0726/web1/blob/master/Evaluating_a_PoS_Tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-AktDJKHYO7",
        "outputId": "39912bd2-9079-4a1c-f09f-c15a508bacb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-04 18:53:47.212177: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.4.0/fr_core_news_sm-3.4.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItKMQcEvkALv"
      },
      "outputs": [],
      "source": [
        "# setting\n",
        "\n",
        "from itertools import chain\n",
        "import spacy\n",
        "fr_model = spacy.load('fr_core_news_sm')\n",
        "from spacy.tokens import Doc\n",
        "from random import sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um2Ln8omGdeL",
        "outputId": "17637add-6ecf-4336-b747-bde3c073369d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'DET', 'NOUN']\n"
          ]
        }
      ],
      "source": [
        "# refercene cell\n",
        "\n",
        "# Spacy predicts pos of tokenized sent\n",
        "def predict_pos(sentence, model): #String -> list\n",
        "  model.tokenizer = lambda x: Doc(model.vocab, x.split())\n",
        "  return [token.pos_ for token in model(sentence)] # reto list of pos\n",
        "    \n",
        "print(predict_pos(\"J' aime le chocolat\", fr_model)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCsHNemSn2l8"
      },
      "outputs": [],
      "source": [
        "# Exo 3\n",
        "\n",
        "def spacy_predicts(sentences): # ls.sentences ==> ls.pose(ls in ls)\n",
        "  poses = [] \n",
        "  for sentence in sentences:\n",
        "    pos = predict_pos(sentence, model = fr_model)\n",
        "    poses.append(pos)\n",
        "  return poses\n",
        " \n",
        "# print( spacy_predicts(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT8BijNXBNpy"
      },
      "outputs": [],
      "source": [
        "#example set 01\n",
        "test_sent = [\"tu me dit quelque chose.\", \"Trop du boulot?\", \"L'art est partout.\"]\n",
        "test_p = spacy_predicts(test_sent)\n",
        "# print(test_p)\n",
        "test_g = [['VERB', 'PRON', 'VERB', 'DET', 'NOUN'], ['ADV', 'ADP', 'NOUN'], ['DET', 'AUX', 'ADJ']]\n",
        "\n",
        "# #example set 01\n",
        "# test_sent = [\"cela signifie que leur consommation énergétique , qui représente actuellement 10 % de la consommation énergétique moyenne de l' UE , enregistrera une forte augmentation à mesure qu' ils exigeront des commodités élémentaires comme l' eau chaude et , peut-être même , l' air conditionné , des moyens de transport et la modernisation de leurs industries .\"]\n",
        "# test_p =  spacy_predicts(test_sent)\n",
        "# # print(test_p)\n",
        "# test_g = [['PRON', 'VERB', 'SCONJ', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'PRON', 'VERB', 'ADV', 'NUM', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'ADJ', 'ADP', 'DET', 'PROPN', 'PUNCT', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'SCONJ', 'PRON', 'VERB', 'DET', 'NOUN', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADJ', 'CCONJ', 'PUNCT', 'ADV', 'ADV', 'PUNCT', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'DET', 'NOUN', 'ADP', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYolZ0U11vlX",
        "outputId": "48032192-08d4-4a60-f625-6a71a829711e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.667\n"
          ]
        }
      ],
      "source": [
        "# Exo 5-1\n",
        "\n",
        "def calculate_sent_accuracy(pred_poses, golden_poses):\n",
        "  nb_corr = 0\n",
        "  # print(list(zip(pred_poses, golden_poses)))\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): \n",
        "   if pred_pos == golden_pos :\n",
        "      nb_corr += 1\n",
        "  \n",
        "  # print(nb_corr)\n",
        "  # print(len(pred_poses))\n",
        "  accuracy = nb_corr / len(pred_poses)\n",
        "  return round(accuracy,3) \n",
        "\n",
        "print(calculate_sent_accuracy(spacy_predicts(test_sent), test_g))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnaA6a-YrHgm",
        "outputId": "bcab964f-a58d-4516-d51f-107e3dcbd0e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.818\n"
          ]
        }
      ],
      "source": [
        "# Exo 5-2\n",
        "\n",
        "def calculate_micro_accuracy(pred_poses, golden_poses):\n",
        "  nb_wd_total = 0\n",
        "  nb_corr = 0\n",
        "\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): # for list in iterable(tuples of list)\n",
        "    for pred_lable, golden_label in zip(pred_pos, golden_pos) : # for element in list\n",
        "      if pred_lable == golden_label:\n",
        "        nb_corr += 1\n",
        "  nb_wd_total = len(list(chain.from_iterable(golden_poses)))\n",
        "  # print(nb_corr)\n",
        "  # print(nb_wd_total)\n",
        "  accuracy = nb_corr / nb_wd_total\n",
        "\n",
        "  # print(list(zip(pred_poses, golden_poses)))\n",
        "  \n",
        "  return round(accuracy,3)\n",
        "  \n",
        "print(calculate_micro_accuracy(spacy_predicts(test_sent), test_g))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOsttNADBuLQ",
        "outputId": "15f4f7b4-75e1-4129-f073-6f8c1153955d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.846\n"
          ]
        }
      ],
      "source": [
        "# Exo 5-3\n",
        "\n",
        "def calculate_macro_accuracy(pred_poses, golden_poses):\n",
        "  nb_pos = 0\n",
        "  nb_corr = 0\n",
        "  # all_poss_poses = [\"NOUN\"] # test\n",
        "  dico_pos_acc = {}\n",
        "\n",
        "  #collect only correct pairs and make into a list \n",
        "  correct_pairs = []\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): # for list in iterable(tuples of list)\n",
        "    # print(list(zip(pred_poses, golden_poses)))\n",
        "    for pred_lable, golden_label in zip(pred_pos, golden_pos) :  # for element in list\n",
        "      if pred_lable == golden_label:\n",
        "        correct_pairs.append((pred_lable, golden_label))\n",
        "\n",
        "  # print(correct_pairs)\n",
        "  # print(len(correct_pairs))\n",
        "  \n",
        " \n",
        "\n",
        "  # calculate nb_pos\n",
        "  \n",
        "  all_poss_poses = [\"PRON\", \"VERB\", \"SCONJ\", \"DET\", \"NOUN\", \"ADJ\", \"PUNCT\", \"ADV\", \"NUM\", \"ADP\", \"AUX\", \"PROPN\"]\n",
        "  for pos in all_poss_poses:\n",
        "  \n",
        "    # calculate nb_corr\n",
        "    for a,b in correct_pairs:\n",
        "      if a == pos:\n",
        "        nb_corr += 1\n",
        "  \n",
        "    for pred_pos, golden_pos in zip(pred_poses, golden_poses):\n",
        "      nb_pos += golden_pos.count(pos)\n",
        "    \n",
        "  # #make dico mapping each pos and it's average of accuracy\n",
        "    dico_pos_acc[pos] = nb_corr / nb_pos\n",
        "\n",
        "  # # calculate average of each label's accuracy, which corresponds to accuracy\n",
        "  accuracy = sum(list(dico_pos_acc.values()))/len(list(all_poss_poses))\n",
        "\n",
        "  # # print(nb_corr)\n",
        "  # print(nb_pos)\n",
        "  # # print(dico_pos_acc)\n",
        "  \n",
        "  return round(accuracy,3)\n",
        "\n",
        "print(calculate_macro_accuracy(spacy_predicts(test_sent), test_g))\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3KHFa6E3uc6",
        "outputId": "5a765248-a03b-4922-9afe-3771e46dc054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456 sentences\n",
            "10044 words\n"
          ]
        }
      ],
      "source": [
        "# Exo 7\n",
        "\n",
        "import json\n",
        "corpus = json.load(open(\"sequoia.test.json\", \"r\"))\n",
        "#corpus is a list of dictionaries, each dictionary contains two keys, tokenized_sentence and gold_tags\n",
        "\n",
        "nb_sent_total = len(corpus)\n",
        "print(\"%d sentences\" %(nb_sent_total))\n",
        "nb_wd_total = 0\n",
        "\n",
        "for i in range(len(corpus)):\n",
        "  nb_wd = len(corpus[i]['gold_labels'])\n",
        "  nb_wd_total += nb_wd\n",
        "print(\"%d words\" %(nb_wd_total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWhbqel_MfTA",
        "outputId": "f5722bb9-45e4-4343-fffc-15c629b45dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.59\n",
            "0.943\n",
            "0.938\n"
          ]
        }
      ],
      "source": [
        "# Exo 8\n",
        "\n",
        "import json\n",
        "corpus = json.load(open(\"sequoia.test.json\", \"r\"))\n",
        "# print(corpus)\n",
        "\n",
        "# convert corpus Sequoia to put in Spacy \n",
        "\n",
        "sentences = [] # list of sent of Seqa (aka question sheet)\n",
        "space = ' '\n",
        "for i in range(len(corpus)):\n",
        "  sentences.append(space.join(corpus[i][\"tokenized_sentence\"]))\n",
        "# print(sentences)\n",
        "\n",
        "tagging_by_spacy = spacy_predicts(sentences) # tag done by Spacy(ls-in-ls) (aka Spacy'answer)\n",
        "# print(spacy_predicts(sentences))\n",
        "\n",
        "golden_tagging = [] # tag done by Seqa (ls-in-ls) (aka answer sheet)\n",
        "for i in range(len(corpus)):\n",
        "  golden_tagging.append((corpus[i][\"gold_labels\"]))\n",
        "\n",
        "sent_n_golden_tagging = list(zip(sentences,golden_tagging)) # list of (sent\"\", golden poses[])\n",
        "\n",
        "# dico mapping sentence to it's golden label (aka Q and A)\n",
        "sent2golden = dict(sent_n_golden_tagging) \n",
        "# print(sent2golden[\"Ceci peut contribuer à maintenir le flux sanguin vers le coeur chez les patients atteints d' angor ou d' une crise cardiaque et à améliorer l' efficacité de leur ICP .\"])\n",
        "\n",
        "\n",
        "print(calculate_sent_accuracy(tagging_by_spacy,golden_tagging))\n",
        "print(calculate_micro_accuracy(tagging_by_spacy,golden_tagging))\n",
        "print(calculate_macro_accuracy(tagging_by_spacy,golden_tagging))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exo 10\n",
        "# calculate error rate\n",
        "\n",
        "def calculate_sent_err_rate(pred_poses, golden_poses):\n",
        "  nb_err = 0\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): \n",
        "    # print(pred_pos, golden_pos)\n",
        "    if pred_pos != golden_pos :\n",
        "      nb_err += 1\n",
        "  \n",
        "  err_rate = nb_err / len(pred_poses)\n",
        "  return round(err_rate,3) \n",
        "\n",
        "\n",
        "def calculate_micro_err_rate(pred_poses, golden_poses):\n",
        "  nb_wd_total = 0\n",
        "  nb_err = 0\n",
        "\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): # for list in iterable(tuples of list)\n",
        "    for pred_lable, golden_label in zip(pred_pos, golden_pos) : # for element in list\n",
        "      if pred_lable != golden_label:\n",
        "        nb_err += 1\n",
        "  nb_wd_total = len(list(chain.from_iterable(golden_poses)))\n",
        "  err_rate = nb_err / nb_wd_total\n",
        "  return round(err_rate,3)\n",
        "\n",
        "# Exo 5-3\n",
        "\n",
        "def calculate_macro_err_rate(pred_poses, golden_poses):\n",
        "  nb_pos = 0\n",
        "  nb_err = 0\n",
        "  # all_poss_poses = [\"NOUN\"] # test\n",
        "  dico_pos_acc = {}\n",
        "\n",
        "  #collect only correct pairs and make into a list \n",
        "  incorrect_pairs = []\n",
        "  for pred_pos, golden_pos in zip(pred_poses, golden_poses): # for list in iterable(tuples of list)\n",
        "    # print(list(zip(pred_poses, golden_poses)))\n",
        "    for pred_lable, golden_label in zip(pred_pos, golden_pos) :  # for element in list\n",
        "      if pred_lable != golden_label:\n",
        "        incorrect_pairs.append((pred_lable, golden_label))\n",
        "  \n",
        "  all_poss_poses = [\"PRON\", \"VERB\", \"SCONJ\", \"DET\", \"NOUN\", \"ADJ\", \"PUNCT\", \"ADV\", \"NUM\", \"ADP\", \"AUX\", \"PROPN\"]\n",
        "  for pos in all_poss_poses:\n",
        "  \n",
        "    # calculate nb_err\n",
        "    for a,b in incorrect_pairs:\n",
        "      if a == pos:\n",
        "        nb_err += 1\n",
        "  \n",
        "    for pred_pos, golden_pos in zip(pred_poses, golden_poses):\n",
        "      nb_pos += golden_pos.count(pos)\n",
        "    \n",
        "  # #make dico mapping each pos and it's average of accuracy\n",
        "    dico_pos_acc[pos] = nb_err / nb_pos\n",
        "\n",
        "  # # calculate average of each label's accuracy, which corresponds to accuracy\n",
        "  err_rate = sum(list(dico_pos_acc.values()))/len(list(all_poss_poses))\n",
        "\n",
        "  return round(err_rate,3)\n",
        "\n",
        "\n",
        "# print(calculate_sent_err_rate(test_p, test_g))  \n",
        "# print(calculate_micro_err_rate(test_p, test_g))\n",
        "# print(calculate_macro_err_rate(test_p, test_g))"
      ],
      "metadata": {
        "id": "4Xvqw16iA2XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#draw only 10 Q\n",
        "\n",
        "sentences = [] # list of sent of Seqa (aka question sheet)\n",
        "space = ' '\n",
        "for i in range(len(corpus)):\n",
        "  sentences.append(space.join(corpus[i][\"tokenized_sentence\"]))\n",
        "ten_sentences = sample(sentences,10)\n",
        "print(ten_sentences)\n",
        "\n",
        "golden_tagging = []\n",
        "for sent in ten_sentences:\n",
        "  golden_tagging.append(sent2golden[sent])\n",
        "\n",
        "print(calculate_sent_err_rate(spacy_predicts(ten_sentences), golden_tagging))\n",
        "print(calculate_micro_err_rate(spacy_predicts(ten_sentences), golden_tagging))\n",
        "print(calculate_macro_err_rate(spacy_predicts(ten_sentences), golden_tagging))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8BoZqk7dCS",
        "outputId": "93eb0c28-0c42-4911-d41a-d4132d5289d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Chez les patients ayant eu une fracture de hanche récente secondaire à un traumatisme modéré , il est recommandé de réaliser l' administration d' Aclasta 2 semaines ou plus après l' intervention sur la fracture ( voir rubrique 5.1 ) .\", 'Le premier retour de familles ( adultes , femmes , enfants ) a lieu par la \" traversée de le Beach \" ( navette fluviale qui effectue les liaisons Brazzaville-Kinshasa ) , et comprend environ 1500 personnes , sous le contrôle de le HCR .', \"Pas moins d' une douzaine d' hommes étaient mobilisés dont l' équipe cynophile .\", 'À le moins une nouvelle fracture vertébrale ( 0-3 ans )', 'Dernier élément non négligeable et pourtant souvent \" oublié par la presse \" .', \"Mais l' introduction effective de l' euro en 2002 va se traduire par une transparence et une concurrence telles que les marchés nationaux vont devoir s' adapter plus rapidement que prévu .\", \"- La substance active est l' acide zolédronique .\", \"Cette visite s' inscrivait dans le cadre de la neuvième rencontre entre les présidents de le Parlement européen et les présidents de les pays candidats , une rencontre qui a été initiée il y a plusieurs années par mes prédécesseurs Enrique Barón Crespo , Klaus Hänsch et José Maria Gil Robles .\", \"Il est , dans ce contexte , paradoxal de constater que certains de les partisans les plus chauds de la libéralisation financière sont en même temps des opposants à l' euro .\", 'Vous devez prévenir votre médecin :']\n",
            "0.5\n",
            "0.031\n",
            "0.029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXgJt7SPxpyL"
      },
      "outputs": [],
      "source": [
        "# Exo 9\n",
        "\n",
        "def partial_evaluation(n, corpus, eval_func): # select n% of corpus and evaluate with the func choosen\n",
        "  \n",
        "  #select n% of question sheet (aka part test question)\n",
        "  sentences = [] \n",
        "  space = ' '\n",
        "  for i in range(len(corpus)):\n",
        "    sentences.append(space.join(corpus[i][\"tokenized_sentence\"]))\n",
        "    partial_sentences = sample(sentences, round(len(sentences) * (n/100)))\n",
        "  \n",
        "  \n",
        "  # print(partial_sentences) \n",
        "\n",
        "  tagging_by_spacy = spacy_predicts(partial_sentences) # tag done by Spacy(ls-in-ls) (aka Spacy'answer)\n",
        "\n",
        "\n",
        "  golden_tagging = [] # answer sheet for part test\n",
        "  for sent in partial_sentences : \n",
        "    golden_tagging.append(sent2golden[sent])\n",
        "  # print(golden_tagging)\n",
        "  \n",
        "  res = eval_func(tagging_by_spacy, golden_tagging) # pred-poses, g-poses\n",
        "  return res\n",
        "  \n",
        "\n",
        "# print(partial_evaluation(10, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_macro_err_rate))\n",
        "# print(partial_evaluation(20, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(30, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(40, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(50, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(60, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(70, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(80, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "# print(partial_evaluation(90, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_sent_err_rate))\n",
        "\n",
        "# Exo 10\n",
        "\n",
        "# err_rates = []\n",
        "# for i in range(1000):\n",
        "#  err_rates.append(partial_evaluation(50, corpus = json.load(open(\"sequoia.test.json\", \"r\")), eval_func = calculate_macro_err_rate))\n",
        "# print(err_rates)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "err_rates = [0.058, 0.06, 0.049, 0.054, 0.062, 0.04, 0.063, 0.056, 0.063, 0.05, 0.064, 0.072, 0.06, 0.056, 0.06, 0.045, 0.05, 0.057, 0.059, 0.058, 0.046, 0.071, 0.047, 0.076, 0.055, 0.052, 0.052, 0.046, 0.052, 0.063, 0.06, 0.064, 0.057, 0.076, 0.061, 0.056, 0.047, 0.068, 0.05, 0.049, 0.057, 0.058, 0.056, 0.063, 0.05, 0.063, 0.053, 0.056, 0.072, 0.053, 0.061, 0.05, 0.054, 0.051, 0.061, 0.058, 0.049, 0.071, 0.059, 0.059, 0.047, 0.066, 0.056, 0.07, 0.049, 0.051, 0.057, 0.057, 0.073, 0.061, 0.058, 0.068, 0.067, 0.064, 0.061, 0.057, 0.052, 0.063, 0.059, 0.068, 0.064, 0.066, 0.053, 0.04, 0.065, 0.055, 0.068, 0.063, 0.055, 0.073, 0.063, 0.041, 0.057, 0.053, 0.07, 0.064, 0.057, 0.07, 0.05, 0.061, 0.06, 0.057, 0.067, 0.073, 0.053, 0.062, 0.054, 0.066, 0.068, 0.058, 0.057, 0.062, 0.047, 0.058, 0.061, 0.05, 0.047, 0.066, 0.071, 0.05, 0.05, 0.047, 0.051, 0.068, 0.055, 0.047, 0.052, 0.045, 0.066, 0.056, 0.059, 0.036, 0.052, 0.07, 0.069, 0.054, 0.06, 0.047, 0.05, 0.059, 0.049, 0.062, 0.055, 0.058, 0.052, 0.069, 0.059, 0.058, 0.063, 0.064, 0.058, 0.042, 0.073, 0.062, 0.063, 0.052, 0.068, 0.057, 0.065, 0.059, 0.066, 0.066, 0.065, 0.053, 0.058, 0.064, 0.06, 0.052, 0.05, 0.043, 0.057, 0.073, 0.061, 0.059, 0.052, 0.053, 0.052, 0.054, 0.054, 0.043, 0.061, 0.036, 0.051, 0.07, 0.047, 0.063, 0.055, 0.069, 0.06, 0.053, 0.052, 0.055, 0.053, 0.062, 0.069, 0.074, 0.063, 0.051, 0.048, 0.059, 0.058, 0.059, 0.063, 0.071, 0.068, 0.049, 0.064, 0.068, 0.058, 0.061, 0.063, 0.064, 0.047, 0.041, 0.054, 0.031, 0.054, 0.055, 0.05, 0.066, 0.054, 0.053, 0.049, 0.064, 0.06, 0.063, 0.056, 0.047, 0.062, 0.067, 0.061, 0.054, 0.054, 0.052, 0.068, 0.057, 0.074, 0.049, 0.065, 0.061, 0.066, 0.063, 0.045, 0.055, 0.06, 0.057, 0.05, 0.046, 0.034, 0.066, 0.055, 0.06, 0.046, 0.048, 0.056, 0.042, 0.066, 0.067, 0.064, 0.046, 0.074, 0.076, 0.056, 0.054, 0.071, 0.072, 0.057, 0.054, 0.067, 0.057, 0.045, 0.04, 0.048, 0.073, 0.064, 0.057, 0.065, 0.051, 0.055, 0.052, 0.053, 0.051, 0.081, 0.058, 0.069, 0.047, 0.067, 0.064, 0.056, 0.053, 0.067, 0.046, 0.057, 0.048, 0.063, 0.066, 0.046, 0.058, 0.062, 0.06, 0.065, 0.054, 0.063, 0.077, 0.063, 0.06, 0.062, 0.069, 0.063, 0.059, 0.063, 0.055, 0.061, 0.049, 0.057, 0.054, 0.048, 0.068, 0.061, 0.043, 0.051, 0.046, 0.079, 0.059, 0.063, 0.053, 0.069, 0.067, 0.056, 0.063, 0.062, 0.063, 0.07, 0.057, 0.068, 0.052, 0.056, 0.055, 0.053, 0.058, 0.061, 0.055, 0.069, 0.052, 0.059, 0.054, 0.048, 0.067, 0.063, 0.071, 0.065, 0.07, 0.042, 0.056, 0.077, 0.049, 0.044, 0.061, 0.063, 0.067, 0.053, 0.074, 0.042, 0.057, 0.052, 0.064, 0.057, 0.064, 0.047, 0.06, 0.05, 0.055, 0.061, 0.066, 0.058, 0.051, 0.055, 0.053, 0.05, 0.053, 0.057, 0.05, 0.054, 0.06, 0.059, 0.055, 0.064, 0.07, 0.048, 0.042, 0.053, 0.069, 0.056, 0.068, 0.063, 0.062, 0.045, 0.048, 0.057, 0.062, 0.058, 0.062, 0.067, 0.069, 0.053, 0.061, 0.069, 0.054, 0.056, 0.049, 0.055, 0.046, 0.051, 0.063, 0.062, 0.069, 0.059, 0.055, 0.051, 0.06, 0.057, 0.047, 0.047, 0.055, 0.056, 0.054, 0.057, 0.062, 0.065, 0.054, 0.064, 0.069, 0.055, 0.07, 0.057, 0.064, 0.071, 0.061, 0.059, 0.07, 0.048, 0.059, 0.055, 0.059, 0.053, 0.066, 0.056, 0.062, 0.046, 0.045, 0.061, 0.043, 0.057, 0.039, 0.062, 0.056, 0.074, 0.059, 0.069, 0.05, 0.05, 0.062, 0.06, 0.05, 0.057, 0.071, 0.067, 0.061, 0.059, 0.065, 0.078, 0.061, 0.069, 0.068, 0.041, 0.059, 0.058, 0.067, 0.053, 0.052, 0.067, 0.074, 0.076, 0.051, 0.059, 0.063, 0.064, 0.057, 0.045, 0.051, 0.052, 0.043, 0.059, 0.055, 0.046, 0.041, 0.06, 0.077, 0.065, 0.058, 0.07, 0.067, 0.07, 0.044, 0.056, 0.056, 0.061, 0.042, 0.064, 0.049, 0.069, 0.051, 0.05, 0.068, 0.058, 0.047, 0.063, 0.075, 0.047, 0.056, 0.056, 0.051, 0.045, 0.061, 0.077, 0.065, 0.053, 0.045, 0.055, 0.053, 0.061, 0.048, 0.066, 0.058, 0.057, 0.066, 0.06, 0.061, 0.057, 0.049, 0.061, 0.07, 0.047, 0.063, 0.056, 0.049, 0.059, 0.048, 0.045, 0.062, 0.048, 0.045, 0.064, 0.061, 0.058, 0.064, 0.077, 0.07, 0.058, 0.05, 0.07, 0.065, 0.059, 0.044, 0.057, 0.075, 0.056, 0.069, 0.051, 0.049, 0.06, 0.062, 0.041, 0.04, 0.062, 0.063, 0.052, 0.051, 0.061, 0.058, 0.076, 0.048, 0.054, 0.052, 0.049, 0.07, 0.071, 0.055, 0.061, 0.049, 0.063, 0.053, 0.061, 0.067, 0.065, 0.057, 0.055, 0.053, 0.062, 0.056, 0.064, 0.052, 0.063, 0.062, 0.057, 0.055, 0.065, 0.056, 0.066, 0.075, 0.066, 0.051, 0.05, 0.05, 0.042, 0.046, 0.054, 0.063, 0.058, 0.058, 0.059, 0.05, 0.069, 0.056, 0.045, 0.062, 0.064, 0.069, 0.07, 0.054, 0.052, 0.071, 0.065, 0.045, 0.066, 0.061, 0.047, 0.06, 0.05, 0.065, 0.051, 0.055, 0.05, 0.066, 0.056, 0.055, 0.048, 0.05, 0.066, 0.052, 0.065, 0.059, 0.058, 0.062, 0.044, 0.052, 0.057, 0.059, 0.049, 0.054, 0.053, 0.057, 0.073, 0.06, 0.048, 0.056, 0.059, 0.053, 0.059, 0.056, 0.059, 0.05, 0.066, 0.069, 0.074, 0.06, 0.052, 0.058, 0.052, 0.064, 0.062, 0.06, 0.053, 0.07, 0.055, 0.044, 0.051, 0.066, 0.065, 0.054, 0.061, 0.063, 0.057, 0.049, 0.056, 0.046, 0.067, 0.067, 0.058, 0.049, 0.056, 0.054, 0.052, 0.059, 0.049, 0.056, 0.055, 0.056, 0.074, 0.071, 0.071, 0.064, 0.061, 0.057, 0.058, 0.063, 0.061, 0.053, 0.046, 0.061, 0.062, 0.057, 0.052, 0.07, 0.069, 0.072, 0.057, 0.048, 0.048, 0.063, 0.052, 0.061, 0.042, 0.06, 0.06, 0.064, 0.073, 0.068, 0.051, 0.062, 0.059, 0.043, 0.047, 0.051, 0.05, 0.055, 0.061, 0.06, 0.054, 0.061, 0.075, 0.059, 0.047, 0.063, 0.076, 0.046, 0.04, 0.07, 0.068, 0.061, 0.058, 0.037, 0.057, 0.05, 0.056, 0.059, 0.052, 0.055, 0.047, 0.065, 0.062, 0.058, 0.045, 0.062, 0.062, 0.069, 0.072, 0.055, 0.049, 0.056, 0.043, 0.062, 0.07, 0.068, 0.065, 0.07, 0.054, 0.053, 0.062, 0.055, 0.047, 0.058, 0.06, 0.061, 0.044, 0.046, 0.047, 0.056, 0.06, 0.065, 0.053, 0.052, 0.058, 0.049, 0.066, 0.048, 0.066, 0.052, 0.049, 0.052, 0.05, 0.059, 0.057, 0.05, 0.06, 0.069, 0.05, 0.059, 0.046, 0.056, 0.056, 0.034, 0.062, 0.057, 0.06, 0.06, 0.062, 0.066, 0.06, 0.06, 0.051, 0.068, 0.058, 0.05, 0.06, 0.064, 0.06, 0.048, 0.051, 0.059, 0.049, 0.064, 0.064, 0.066, 0.067, 0.059, 0.064, 0.064, 0.073, 0.05, 0.073, 0.068, 0.068, 0.049, 0.062, 0.047, 0.047, 0.047, 0.053, 0.061, 0.069, 0.053, 0.06, 0.064, 0.058, 0.068, 0.061, 0.054, 0.052, 0.053, 0.067, 0.042, 0.061, 0.055, 0.068, 0.067, 0.059, 0.053, 0.068, 0.064, 0.055, 0.072, 0.06, 0.047, 0.058, 0.043, 0.039, 0.068, 0.051, 0.054, 0.065, 0.051, 0.065, 0.057, 0.069, 0.067, 0.058, 0.052, 0.057, 0.06, 0.049, 0.055, 0.066, 0.061, 0.051, 0.049, 0.05, 0.06, 0.062, 0.045, 0.071, 0.045, 0.057, 0.048, 0.056, 0.055, 0.068, 0.056, 0.05, 0.069, 0.069, 0.059, 0.055, 0.055, 0.064, 0.057, 0.068, 0.061, 0.058, 0.058, 0.035, 0.053, 0.055, 0.056, 0.072, 0.061, 0.036, 0.06, 0.053, 0.056, 0.065, 0.043, 0.079, 0.063, 0.054, 0.066, 0.068, 0.067, 0.056, 0.038, 0.07, 0.052, 0.061, 0.061, 0.066, 0.067, 0.058, 0.045, 0.052, 0.057, 0.059, 0.061, 0.049, 0.059, 0.063, 0.046, 0.076, 0.05, 0.062, 0.067, 0.058, 0.054, 0.056, 0.058, 0.054, 0.06, 0.057, 0.047, 0.053, 0.044, 0.05, 0.066, 0.055, 0.059, 0.059, 0.047, 0.065, 0.054, 0.052, 0.063, 0.068, 0.054, 0.06, 0.049, 0.074, 0.063, 0.056, 0.06, 0.047, 0.057]\n",
        "plt.hist(err_rates)\n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Tn41lNln_gym",
        "outputId": "e730a076-81a5-4bbb-c09b-97a63fa41e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Exo 12\n",
        "# corpus_mcft = json.load(open(\"minecraft.json\", \"r\"))\n",
        "# corpus_prst = json.load(open(\"parisstories.test.json\", \"r\"))\n",
        "# corpus_gsd = json.load(open(\"gsd.test.json\", \"r\"))\n",
        "\n",
        "# print(partial_evaluation(100, corpus_prst, calculate_macro_err_rate))\n",
        "# print(partial_evaluation(100, corpus_gsd, calculate_macro_err_rate))"
      ],
      "metadata": {
        "id": "OZiqzHhBBTOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1RO_CSITA0qcQMvke0dYf3FLiGP-tWYva",
      "authorship_tag": "ABX9TyPOa35H5Eo1wLGas4In/DmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}